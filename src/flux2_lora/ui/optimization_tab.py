"""
Optimization tab for the Gradio interface.

Provides hyperparameter optimization capabilities using Optuna.
"""

import os
import json
import tempfile
import threading
import time
from pathlib import Path
from typing import TYPE_CHECKING, Dict, Any, Optional

import gradio as gr

if TYPE_CHECKING:
    from .gradio_app import LoRATrainingApp

from .help_utils import help_system


def opt_generate_recommendations(results: Dict[str, Any], n_trials: int) -> str:
    best_score = results.get("best_score", 0)

    if best_score >= 0.8:
        return "üéâ **Excellent results!** Your optimization found very high-quality parameters. Use the best_config.yaml for production training."
    elif best_score >= 0.6:
        return "üëç **Good results!** The optimized parameters should provide noticeable improvements. Download and use best_config.yaml."
    elif best_score >= 0.4:
        return "ü§î **Fair results.** Consider improving your dataset quality before production training."
    else:
        return "‚ö†Ô∏è **Poor results.** Check dataset quality and consider different optimization settings."


def create_optimization_tab(app: "LoRATrainingApp"):
    """
    Create the optimization tab interface.

    Args:
        app: Main application instance
    """
    # Help section (collapsible)
    with gr.Accordion("üí° Optimization Help & Tips", open=False):
        gr.Markdown(
            "**Hyperparameter Optimization** automatically finds the best LoRA training settings for your dataset using Bayesian optimization."
        )

    with gr.Row():
        with gr.Column(scale=1):
            # Left column: Optimization setup
            gr.Markdown("## ‚öôÔ∏è Optimization Setup")

            with gr.Group():
                gr.Markdown("### Dataset")

                # Dataset selection
                opt_dataset_source = gr.Radio(
                    choices=["Upload ZIP", "Local Directory"],
                    value="Upload ZIP",
                    label="Dataset Source",
                    info="Dataset to use for optimization trials",
                )

                opt_dataset_upload = gr.File(
                    label="Upload Dataset (ZIP)",
                    file_types=[".zip"],
                    visible=True,
                    info="Upload a ZIP file containing your training dataset",
                )

                opt_dataset_path = gr.Textbox(
                    label="Dataset Directory Path",
                    placeholder="/path/to/dataset",
                    visible=False,
                    info="Local path to your dataset directory",
                )

                opt_dataset_status = gr.Textbox(
                    label="Dataset Status",
                    value="No dataset selected",
                    interactive=False,
                    info="Shows validation status of selected dataset",
                )

                gr.Markdown("### Optimization Settings")

                # Optimization parameters
                opt_trials = gr.Slider(
                    minimum=5,
                    maximum=100,
                    value=30,
                    step=5,
                    label="Number of Trials",
                    info="How many different parameter combinations to test. More trials = better results but longer time. 20-50 trials recommended.",
                )

                opt_max_steps = gr.Slider(
                    minimum=200,
                    maximum=1000,
                    value=500,
                    step=50,
                    label="Steps per Trial",
                    info="Training steps for each optimization trial. Shorter = faster optimization but potentially less accurate results.",
                )

                opt_timeout = gr.Number(
                    label="Timeout (hours)",
                    value=None,
                    minimum=0.1,
                    info="Optional: Automatically stop optimization after this many hours to prevent runaway processes",
                )

                opt_study_name = gr.Textbox(
                    label="Study Name",
                    value="flux2_lora_optimization",
                    info="Unique name for this optimization study. Used for saving/loading progress across sessions.",
                )

                # Output settings
                opt_output_dir = gr.Textbox(
                    label="Output Directory",
                    value="./optimization_results",
                    info="Directory where optimization results, trial data, and best configuration will be saved",
                )

                # Preset configurations
                with gr.Accordion("üéØ Quick Presets", open=False):
                    gr.Markdown(
                        "**Quick (20 trials)**: Fast optimization for testing. **Standard (50 trials)**: Recommended for production. **Maximum (100 trials)**: Best results with longest time."
                    )

                    # Preset buttons
                    with gr.Row():
                        quick_preset = gr.Button("‚ö° Quick (20 trials)", size="sm")
                        standard_preset = gr.Button("üéØ Standard (50 trials)", size="sm")
                        max_preset = gr.Button("üèÜ Maximum (100 trials)", size="sm")

                gr.Markdown("### Optimization Controls")

                # Control buttons
                opt_start_btn = gr.Button(
                    "üöÄ Start Optimization",
                    variant="primary",
                    size="lg",
                    info="Begin hyperparameter optimization (may take several hours)",
                )

                opt_stop_btn = gr.Button(
                    "‚èπÔ∏è Stop Optimization",
                    variant="stop",
                    interactive=False,
                    info="Stop the current optimization process",
                )

                # Status
                opt_status = gr.Textbox(
                    label="Optimization Status",
                    value="Ready to optimize",
                    interactive=False,
                    lines=3,
                    info="Current optimization progress and status",
                )

        with gr.Column(scale=2):
            # Right column: Results and monitoring
            gr.Markdown("## üìä Optimization Progress")

            with gr.Group():
                # Progress visualization
                opt_progress_bar = gr.Slider(
                    minimum=0,
                    maximum=100,
                    value=0,
                    label="Optimization Progress (%)",
                    interactive=False,
                    info="Overall completion percentage of optimization",
                )

                opt_current_trial = gr.Textbox(
                    label="Current Trial",
                    value="0 / 0",
                    interactive=False,
                    info="Current trial number and total trials",
                )

                opt_best_score = gr.Textbox(
                    label="Best Score Found",
                    value="No results yet",
                    interactive=False,
                    info="Highest quality score achieved so far",
                )

                # Optimization history plot
                opt_history_plot = gr.LinePlot(
                    label="Optimization History",
                    x="Trial",
                    y="Score",
                    title="Quality Score vs Trial Number",
                    info="Shows how optimization quality improves over trials",
                )

            # Results section
            gr.Markdown("### üìã Optimization Results")

            with gr.Tabs():
                with gr.TabItem("üèÜ Best Parameters"):
                    opt_best_params = gr.JSON(
                        label="Best Hyperparameters",
                        value={},
                        info="Optimal parameter combination found by the optimization process",
                    )

                    # Download button for best config
                    download_best_config = gr.File(
                        label="Download Best Config",
                        file_count="single",
                        visible=False,
                        info="Download the optimized configuration as a YAML file for production training",
                    )

                    download_btn = gr.Button(
                        "üì• Download Best Config",
                        variant="secondary",
                        info="Download the best_config.yaml file for use in production training",
                    )

                with gr.TabItem("üìä Trial History"):
                    opt_trial_history = gr.Dataframe(
                        headers=["Trial", "Score", "Rank", "Alpha", "LR", "Batch Size", "Grad Acc"],
                        value=[],
                        datatype=[
                            "number",
                            "number",
                            "number",
                            "number",
                            "number",
                            "number",
                            "number",
                        ],
                        label="Trial Results",
                        info="Detailed results from all optimization trials. Higher scores are better.",
                    )

                    # Trial analysis
                    with gr.Accordion("üìà Trial Analysis", open=False):
                        gr.Markdown(
                            "**Score**: Quality metric (0-1). **Rank/Alpha**: Model capacity. **LR**: Learning rate. **Batch Size**: Images per step. Focus on highest-scoring trials."
                        )

                with gr.TabItem("üìà Parameter Importance"):
                    opt_param_importance = gr.Plot(
                        label="Parameter Importance",
                        info="Shows which parameters had the most impact on optimization results",
                    )

                    importance_explanation = gr.Markdown(
                        "This chart shows which parameters had the most impact on results. Focus tuning efforts on the highest bars."
                    )

                with gr.TabItem("üí° Recommendations"):
                    opt_recommendations = gr.Markdown(
                        value="No optimization completed yet. Run optimization to see recommendations.",
                        info="Personalized recommendations based on your optimization results",
                    )

                with gr.TabItem("üìä Trial History"):
                    opt_trial_history = gr.Dataframe(
                        headers=["Trial", "Score", "Rank", "Alpha", "LR", "Batch Size", "Grad Acc"],
                        value=[],
                        datatype=[
                            "number",
                            "number",
                            "number",
                            "number",
                            "number",
                            "number",
                            "number",
                        ],
                        label="Trial Results",
                        info="Detailed results from all optimization trials",
                    )

                with gr.TabItem("üìà Parameter Importance"):
                    opt_param_importance = gr.Plot(
                        label="Parameter Importance",
                        info="Shows which parameters had the most impact on results",
                    )

    # State variables
    opt_active = gr.State(False)
    opt_results = gr.State({})
    opt_dataset_path = gr.State(None)
    opt_config_file = gr.State(None)

    # Preset handlers
    def apply_quick_preset():
        return {
            opt_trials: 20,
            opt_max_steps: 300,
            opt_timeout: 8.0,
        }

    def apply_standard_preset():
        return {
            opt_trials: 50,
            opt_max_steps: 500,
            opt_timeout: None,
        }

    def apply_max_preset():
        return {
            opt_trials: 100,
            opt_max_steps: 500,
            opt_timeout: None,
        }

    quick_preset.click(
        fn=apply_quick_preset,
        outputs=[opt_trials, opt_max_steps, opt_timeout],
    )

    standard_preset.click(
        fn=apply_standard_preset,
        outputs=[opt_trials, opt_max_steps, opt_timeout],
    )

    max_preset.click(
        fn=apply_max_preset,
        outputs=[opt_trials, opt_max_steps, opt_timeout],
    )

    # Event handlers
    def opt_update_dataset_visibility(source):
        if source == "Upload ZIP":
            return gr.update(visible=True), gr.update(visible=False)
        else:
            return gr.update(visible=False), gr.update(visible=True)

    opt_dataset_source.change(
        fn=opt_update_dataset_visibility,
        inputs=[opt_dataset_source],
        outputs=[opt_dataset_upload, opt_dataset_path],
    )

    # Dataset upload handler
    def opt_handle_dataset_upload(file_obj):
        if file_obj:
            from .training_tab import handle_dataset_upload

            status, path = handle_dataset_upload(app, file_obj)
            return status, path
        return "No file uploaded", None

    opt_dataset_upload.change(
        fn=opt_handle_dataset_upload,
        inputs=[opt_dataset_upload],
        outputs=[opt_dataset_status, opt_dataset_path],
    )

    # Dataset path handler
    def opt_handle_dataset_path(path):
        if path and path.strip():
            from .training_tab import handle_dataset_path

            status, dataset_path = handle_dataset_path(app, path.strip())
            return status
        return "No dataset path provided"

    opt_dataset_path.change(
        fn=opt_handle_dataset_path,
        inputs=[opt_dataset_path],
        outputs=[opt_dataset_status],
    )

    # Start optimization handler
    def opt_start_optimization_handler(
        trials,
        max_steps,
        timeout,
        study_name,
        output_dir,
        opt_active,
        opt_results,
        opt_dataset_path,
    ):
        if opt_active:
            return "Optimization is already running", opt_active, opt_results

        if not opt_dataset_path:
            return (
                "‚ùå No dataset selected. Please upload or specify a dataset path.",
                opt_active,
                opt_results,
            )

        try:
            # Check if Optuna is available
            import optuna
        except ImportError:
            return (
                "‚ùå Optuna is required for optimization. Install with: pip install optuna",
                opt_active,
                opt_results,
            )

        # Validate output directory
        output_path = Path(output_dir)
        try:
            output_path.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            return f"‚ùå Cannot create output directory: {e}", opt_active, opt_results

        # Start optimization in background
        def optimization_thread():
            try:
                from flux2_lora.optimization import create_optimizer

                app.update_training_state(
                    "opt_status", f"üöÄ Starting optimization with {trials} trials..."
                )

                # Create optimizer
                optimizer = create_optimizer(
                    n_trials=int(trials),
                    dataset_path=opt_dataset_path,
                    output_dir=output_dir,
                    timeout_hours=timeout if timeout and timeout > 0 else None,
                    max_steps=int(max_steps),
                )

                # Progress callback
                def progress_callback(trial_number, total_trials, score=None, params=None):
                    progress = (trial_number / total_trials) * 100
                    app.update_training_state("opt_progress", progress)
                    app.update_training_state(
                        "opt_current_trial", f"{trial_number} / {total_trials}"
                    )

                    if score is not None:
                        app.update_training_state("opt_best_score", ".4f")

                    # Update trial history (simplified for UI)
                    if params:
                        app.update_training_state("opt_latest_params", params)

                    # Update status with progress
                    app.update_training_state(
                        "opt_status",
                        f"üîÑ Running trial {trial_number}/{total_trials} | "
                        f"Progress: {progress:.1f}% | "
                        f"Best score: {app.get_training_state('opt_best_score', 'N/A')}",
                    )

                # Run optimization (this will be implemented with progress callbacks)
                results = optimizer.optimize(dataset_path=opt_dataset_path, study_name=study_name)

                # Generate recommendations
                recommendations = opt_generate_recommendations(results, trials)

                app.update_training_state("opt_results", results)
                app.update_training_state("opt_recommendations", recommendations)
                app.update_training_state(
                    "opt_status",
                    f"‚úÖ Optimization completed! Best score: {results['best_score']:.4f}",
                )

                # Set config file path for download
                config_path = Path(output_dir) / "best_config.yaml"
                if config_path.exists():
                    app.update_training_state("opt_config_file", str(config_path))

            except Exception as e:
                app.update_training_state("opt_status", f"‚ùå Optimization failed: {str(e)}")
            finally:
                app.update_training_state("opt_active", False)

        # Start thread
        thread = threading.Thread(target=optimization_thread, daemon=True)
        thread.start()

        return (
            f"üöÄ Optimization started with {trials} trials! This may take several hours.",
            True,
            {},
        )

    opt_start_btn.click(
        fn=opt_start_optimization_handler,
        inputs=[
            opt_trials,
            opt_max_steps,
            opt_timeout,
            opt_study_name,
            opt_output_dir,
            opt_active,
            opt_results,
            opt_dataset_path,
        ],
        outputs=[opt_status, opt_active, opt_results],
    )

    # Stop optimization handler
    def opt_stop_optimization_handler(opt_active):
        if not opt_active:
            return "No optimization is currently running", opt_active

        # Set stop flag (implement in optimizer)
        app.update_training_state("opt_should_stop", True)
        return "‚èπÔ∏è Stopping optimization...", opt_active

    opt_stop_btn.click(
        fn=opt_stop_optimization_handler,
        inputs=[opt_active],
        outputs=[opt_status, opt_active],
    )

    # Download handler
    def opt_download_config(opt_config_file):
        if opt_config_file and Path(opt_config_file).exists():
            return opt_config_file
        return None

    download_btn.click(
        fn=opt_download_config,
        inputs=[opt_config_file],
        outputs=[download_best_config],
    )

    # Update UI periodically
    def opt_update_ui():
        opt_active = app.get_training_state("opt_active", False)
        progress = app.get_training_state("opt_progress", 0.0)
        current_trial = app.get_training_state("opt_current_trial", "0 / 0")
        best_score = app.get_training_state("opt_best_score", "No results yet")
        status = app.get_training_state("opt_status", "Ready to optimize")
        results = app.get_training_state("opt_results", {})
        recommendations = app.get_training_state(
            "opt_recommendations", "No optimization completed yet."
        )
        config_file = app.get_training_state("opt_config_file")

        # Prepare history data
        history_data = []
        if results and "trials_data" in results:
            for trial in results["trials_data"][:20]:
                if trial.get("state") == "COMPLETE":
                    params = trial.get("params", {})
                    history_data.append(
                        [
                            trial.get("number", 0),
                            trial.get("value", 0),
                            params.get("rank", 0),
                            params.get("alpha", 0),
                            params.get("learning_rate", 0),
                            params.get("batch_size", 0),
                            params.get("gradient_accumulation", 0),
                        ]
                    )

        return (
            progress,
            current_trial,
            best_score,
            status,
            results.get("best_params", {}),
            history_data,
            recommendations,
            config_file if config_file and Path(config_file).exists() else None,
            gr.update(interactive=not opt_active),
            gr.update(interactive=opt_active),
            gr.update(visible=bool(config_file and Path(config_file).exists())),
        )

    # Set up periodic UI updates
    opt_timer = gr.Timer(2.0)
    opt_timer.tick(
        fn=opt_update_ui,
        outputs=[
            opt_progress_bar,
            opt_current_trial,
            opt_best_score,
            opt_status,
            opt_best_params,
            opt_trial_history,
            opt_recommendations,
            opt_config_file,
            opt_start_btn,
            opt_stop_btn,
            download_best_config,
        ],
    )
