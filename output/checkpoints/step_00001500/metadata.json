{
  "step": 1500,
  "loss": 0.2303498089313507,
  "timestamp": 1766994942.4256275,
  "config": {
    "model": {
      "base_model": "/home/azureuser/flux.2-dev",
      "dtype": "bfloat16",
      "device": "cuda:0",
      "cache_dir": null,
      "torch_compile": true,
      "attention_implementation": "default"
    },
    "lora": {
      "rank": 32,
      "alpha": 16.0,
      "dropout": 0.0,
      "target_modules": [
        "to_k",
        "to_q",
        "to_v",
        "to_out.0"
      ],
      "use_dora": false,
      "trigger_word": null
    },
    "training": {
      "learning_rate": 0.0002,
      "batch_size": 4,
      "max_steps": 1800,
      "gradient_accumulation_steps": 4,
      "optimizer": "adamw",
      "scheduler": "cosine",
      "warmup_steps": 150,
      "max_grad_norm": 1.0,
      "mixed_precision": "bf16",
      "gradient_checkpointing": true,
      "seed": 42
    },
    "data": {
      "dataset_path": "./data",
      "resolution": 1024,
      "caption_format": "auto",
      "center_crop": true,
      "random_flip": false,
      "num_workers": 4,
      "pin_memory": true,
      "prefetch_factor": 2,
      "cache_images": false,
      "validate_captions": true,
      "min_caption_length": 3,
      "max_caption_length": 1000
    },
    "validation": {
      "enable": false,
      "prompts": [
        "A photo of [TRIGGER_WORD] smiling",
        "A portrait of [TRIGGER_WORD] in natural lighting",
        "A close-up photo of [TRIGGER_WORD]",
        "[TRIGGER_WORD] wearing a black t-shirt",
        "A candid shot of [TRIGGER_WORD] outdoors",
        "A professional headshot of [TRIGGER_WORD]",
        "[TRIGGER_WORD] with different expressions"
      ],
      "num_inference_steps": 25,
      "guidance_scale": 7.5,
      "every_n_steps": 100,
      "num_samples": 2
    },
    "output": {
      "output_dir": "./output",
      "checkpoint_every_n_steps": 300,
      "checkpoints_limit": 8,
      "save_model_config": true
    },
    "logging": {
      "log_level": "INFO",
      "log_dir": "./logs",
      "tensorboard": true,
      "wandb": false,
      "wandb_project": "flux2-lora-character",
      "log_every_n_steps": 10,
      "enable_quality_metrics": true
    },
    "security": {
      "max_file_size_mb": 50,
      "allowed_extensions": [
        ".jpg",
        ".jpeg",
        ".png",
        ".webp",
        ".txt",
        ".json"
      ],
      "max_training_time_hours": 24.0,
      "memory_limit_gb": 80
    },
    "callbacks": {
      "enable_checkpoint": true,
      "checkpoint_every_n_steps": 500,
      "checkpoint_save_best_only": false,
      "checkpoint_monitor_metric": "loss",
      "checkpoint_save_top_k": 3,
      "enable_early_stopping": false,
      "early_stopping_monitor": "validation_loss",
      "early_stopping_patience": 10,
      "early_stopping_min_delta": 0.001,
      "early_stopping_restore_best": true,
      "enable_validation_callback": true,
      "validation_callback_every_n_steps": 100,
      "validation_callback_log_images": true,
      "enable_lr_scheduler_callback": true,
      "lr_scheduler_step_interval": "step"
    },
    "augmentation": {
      "enabled": false,
      "probability": 0.5,
      "preserve_quality": true,
      "max_augmentations_per_sample": 3,
      "image_augmentations": {},
      "text_augmentations": {}
    },
    "memory_optimization": {
      "quantization": {
        "enabled": false,
        "bits": 8,
        "compute_dtype": "bfloat16"
      },
      "enable_attention_slicing": true,
      "attention_slice_size": "auto",
      "enable_vae_slicing": true,
      "enable_vae_tiling": true,
      "sequential_cpu_offload": false
    }
  },
  "metadata": {
    "step": 1500,
    "metrics": {
      "loss": 0.2303498089313507,
      "learning_rate": 0.0002,
      "grad_norm": 0.127347011749109,
      "memory_usage": 62518.3505859375,
      "step_time": 24.81944489479065
    },
    "is_final": false
  },
  "is_best": false,
  "lora_saved": true,
  "optimizer_saved": true,
  "scheduler_saved": true,
  "checkpoint_metadata": {
    "version": "1.0",
    "model_type": "flux2_lora",
    "pytorch_version": "2.9.1+cu128",
    "cuda_available": true,
    "device": "cuda:0",
    "dtype": "torch.bfloat16"
  }
}